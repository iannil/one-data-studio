# Bisheng API 模拟服务
# 用于 PoC 阶段验证应用编排功能

---
# Bisheng API ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: bisheng-api-config
  namespace: one-data-bisheng
data:
  app.py: |
    import os
    import requests
    from flask import Flask, jsonify, request

    app = Flask(__name__)

    # 配置
    ALDATA_API_URL = os.getenv(
        "ALDATA_API_URL",
        "http://alldata-api.one-data-alldata.svc.cluster.local:8080"
    )
    CUBE_API_URL = os.getenv(
        "CUBE_API_URL",
        "http://vllm-serving.one-data-cube.svc.cluster.local:8000"
    )

    @app.route("/api/v1/health")
    def health():
        """健康检查"""
        return jsonify({
            "code": 0,
            "message": "healthy",
            "service": "bisheng-api",
            "version": "1.0.0",
            "connections": {
                "alldata_api": ALDATA_API_URL,
                "cube_api": CUBE_API_URL
            }
        })

    @app.route("/api/v1/chat", methods=["POST"])
    def chat():
        """聊天接口 - 调用 Cube 模型服务"""
        data = request.json
        message = data.get("message", "")
        if not message:
            return jsonify({"code": 40001, "message": "Message is required"}), 400

        try:
            # 调用 Cube 模型服务（OpenAI 兼容 API）
            response = requests.post(
                f"{CUBE_API_URL}/v1/chat/completions",
                json={
                    "model": "gpt2",
                    "messages": [{"role": "user", "content": message}],
                    "max_tokens": 500,
                    "temperature": 0.7
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                reply = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                return jsonify({
                    "code": 0,
                    "message": "success",
                    "data": {
                        "reply": reply,
                        "model": result.get("model"),
                        "usage": result.get("usage", {})
                    }
                })
            else:
                return jsonify({
                    "code": 50001,
                    "message": f"Model service error: {response.status_code}"
                }), 500

        except requests.RequestException as e:
            return jsonify({
                "code": 50002,
                "message": f"Failed to connect to model service: {str(e)}"
            }), 503

    @app.route("/api/v1/datasets", methods=["GET"])
    def list_datasets():
        """获取数据集列表 - 调用 Alldata API"""
        try:
            response = requests.get(
                f"{ALDATA_API_URL}/api/v1/datasets",
                timeout=10
            )
            return jsonify(response.json()), response.status_code
        except requests.RequestException as e:
            return jsonify({
                "code": 50003,
                "message": f"Failed to connect to Alldata API: {str(e)}"
            }), 503

    @app.route("/api/v1/datasets/<dataset_id>", methods=["GET"])
    def get_dataset(dataset_id: str):
        """获取数据集详情 - 调用 Alldata API"""
        try:
            response = requests.get(
                f"{ALDATA_API_URL}/api/v1/datasets/{dataset_id}",
                timeout=10
            )
            return jsonify(response.json()), response.status_code
        except requests.RequestException as e:
            return jsonify({
                "code": 50003,
                "message": f"Failed to connect to Alldata API: {str(e)}"
            }), 503

    @app.route("/api/v1/rag/query", methods=["POST"])
    def rag_query():
        """RAG 查询接口（模拟）"""
        data = request.json
        question = data.get("question", "")

        # 模拟 RAG 流程
        # 1. 从向量数据库检索相关文档
        # 2. 构建带上下文的 Prompt
        # 3. 调用模型生成回答

        context = """
        相关文档片段：
        ONE-DATA-STUDIO 是一个融合了 Alldata（数据治理）、Cube Studio（模型训练）、Bisheng（应用编排）的企业级 AI 平台。
        """

        try:
            response = requests.post(
                f"{CUBE_API_URL}/v1/chat/completions",
                json={
                    "model": "gpt2",
                    "messages": [
                        {
                            "role": "system",
                            "content": f"你是一个智能助手。请根据以下上下文回答用户问题：\n{context}"
                        },
                        {"role": "user", "content": question}
                    ],
                    "max_tokens": 500
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                reply = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                return jsonify({
                    "code": 0,
                    "message": "success",
                    "data": {
                        "answer": reply,
                        "sources": ["docs/one-data-studio.md"]
                    }
                })
            else:
                return jsonify({
                    "code": 50001,
                    "message": f"Model service error: {response.status_code}"
                }), 500

        except requests.RequestException as e:
            return jsonify({
                "code": 50002,
                "message": f"Failed to connect to model service: {str(e)}"
            }), 503

    @app.route("/api/v1/workflows", methods=["GET"])
    def list_workflows():
        """获取工作流列表"""
        workflows = [
            {
                "id": "wf-001",
                "name": "知识问答助手",
                "description": "基于 RAG 的文档问答",
                "status": "running"
            },
            {
                "id": "wf-002",
                "name": "数据分析助手",
                "description": "Text-to-SQL 数据查询",
                "status": "stopped"
            }
        ]
        return jsonify({
            "code": 0,
            "message": "success",
            "data": {"workflows": workflows}
        })

    if __name__ == "__main__":
        app.run(host="0.0.0.0", port=8080, debug=True)

---
# Bisheng API Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bisheng-api
  namespace: one-data-bisheng
  labels:
    app: bisheng-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: bisheng-api
  template:
    metadata:
      labels:
        app: bisheng-api
    spec:
      containers:
      - name: api
        image: python:3.10-slim
        command:
        - /bin/sh
        - -c
        args:
        - |
          pip install flask requests -q && \
          python /app/app.py
        env:
        - name: PYTHONUNBUFFERED
          value: "true"
        - name: ALDATA_API_URL
          value: "http://alldata-api.one-data-alldata.svc.cluster.local:8080"
        - name: CUBE_API_URL
          value: "http://vllm-serving.one-data-cube.svc.cluster.local:8000"
        ports:
        - name: http
          containerPort: 8080
        livenessProbe:
          httpGet:
            path: /api/v1/health
            port: 8080
          initialDelaySeconds: 10
        readinessProbe:
          httpGet:
            path: /api/v1/health
            port: 8080
          initialDelaySeconds: 5
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: config
          mountPath: /app
      volumes:
      - name: config
        configMap:
          name: bisheng-api-config

---
# Bisheng API Service
apiVersion: v1
kind: Service
metadata:
  name: bisheng-api
  namespace: one-data-bisheng
spec:
  selector:
    app: bisheng-api
  ports:
  - name: http
    port: 8080
    targetPort: 8080
  type: ClusterIP

---
# Bisheng Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: bisheng-ingress
  namespace: one-data-bisheng
spec:
  ingressClassName: nginx
  rules:
  - host: bisheng.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: bisheng-api
            port:
              number: 8080
