# ONE-DATA-STUDIO Helm Chart Values
# 全局配置
#
# ============================================
# SECURITY NOTICE
# ============================================
# Before deploying to production:
# 1. Set global.environment to "production"
# 2. Configure ALL required credentials via --set or external secrets
# 3. Enable TLS on all ingress resources
# 4. Use values-production.yaml overlay for production settings
#
# Example production deployment:
#   helm install one-data ./deploy/helm/charts/one-data \
#     -f values.yaml \
#     -f values-production.yaml \
#     --set services.jwtSecretKey=$(openssl rand -base64 32) \
#     --set infrastructure.minio.credentials.rootUser=$MINIO_USER \
#     --set infrastructure.minio.credentials.rootPassword=$MINIO_PASS \
#     --set infrastructure.mysql.database.password=$MYSQL_PASS \
#     --set infrastructure.redis.password=$REDIS_PASS \
#     --set monitoring.grafana.adminPassword=$GRAFANA_PASS
#
# For external secrets management:
#   - Sealed Secrets: https://sealed-secrets.netlify.app/
#   - External Secrets: https://external-secrets.io/
#   - HashiCorp Vault: https://www.vaultproject.io/
# ============================================

global:
  # 镜像仓库
  imageRegistry: ""

  # 镜像拉取密钥
  imagePullSecrets: []

  # 环境标签 - IMPORTANT: Set to "production" for production deployments
  # This triggers credential validation in templates
  environment: "dev"

  # 存储配置
  storageClass:
    data: "standard-hdd"
    database: "fast-ssd"

# ============================================
# 基础设施
# ============================================

infrastructure:
  enabled: true

  # MinIO 对象存储
  minio:
    enabled: true
    image:
      repository: quay.io/minio/minio
      tag: RELEASE.2023-12-23T07-19-11Z
    persistence:
      size: 100Gi
      storageClass: standard-hdd
    resources:
      requests:
        memory: 512Mi
        cpu: 250m
      limits:
        memory: 2Gi
        cpu: 1000m
    credentials:
      # REQUIRED: Must be set via --set or values override
      # DO NOT use default values in production
      # Example: helm install ... --set infrastructure.minio.credentials.rootUser=$MINIO_ROOT_USER
      rootUser: ""  # REQUIRED: set via MINIO_ROOT_USER
      rootPassword: ""  # REQUIRED: set via MINIO_ROOT_PASSWORD
      # Validation: Template will fail if these are empty in production

  # MySQL 数据库
  mysql:
    enabled: true
    image:
      repository: mysql
      tag: "8.0.36"  # Pinned version for reproducibility
    persistence:
      size: 50Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 4Gi
        cpu: 2000m
    database:
      name: one_data
      user: one_data
      # REQUIRED: Must be set via --set or values override
      # Example: helm install ... --set infrastructure.mysql.database.password=$MYSQL_PASSWORD
      password: ""  # REQUIRED: set via MYSQL_PASSWORD

  # Redis 缓存
  redis:
    enabled: true
    image:
      repository: redis
      tag: "7.0.15-alpine"  # Pinned version for reproducibility
    persistence:
      size: 10Gi
      storageClass: fast-ssd
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      limits:
        memory: 1Gi
        cpu: 500m
    # REQUIRED: Must be set via --set or values override
    # Example: helm install ... --set infrastructure.redis.password=$REDIS_PASSWORD
    password: ""  # REQUIRED: set via REDIS_PASSWORD

  # Milvus 向量数据库（高可用集群配置）
  milvus:
    enabled: true
    image:
      repository: milvusdb/milvus
      tag: v2.3.3

    # 集群模式配置
    mode: "cluster"  # standalone, cluster
    replicas:
      rootCoord: 3
      dataCoord: 3
      queryCoord: 2
      indexCoord: 2
      dataNode: 3
      queryNode: 3
      indexNode: 2
      proxy: 3

    # 依赖服务
    dependencies:
      etcd:
        enabled: true
        endpoint: "etcd.one-data-infra.svc.cluster.local:2379"
      pulsar:
        enabled: true
        endpoint: "pulsar.one-data-infra.svc.cluster.local:6650"
      minio:
        enabled: true
        endpoint: "minio.one-data-infra.svc.cluster.local:9000"
        bucket: "milvus"

    # 持久化配置
    persistence:
      enabled: true
      dataNode:
        size: 50Gi
        storageClass: fast-ssd
      queryNode:
        size: 20Gi
        storageClass: fast-ssd
      indexNode:
        size: 30Gi
        storageClass: fast-ssd
      dataCoord:
        size: 10Gi
        storageClass: fast-ssd

    # 资源配置
    resources:
      rootCoord:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "500m"
      dataCoord:
        requests:
          memory: "512Mi"
          cpu: "200m"
        limits:
          memory: "1Gi"
          cpu: "1000m"
      queryCoord:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "500m"
      indexCoord:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "500m"
      dataNode:
        requests:
          memory: "1Gi"
          cpu: "500m"
        limits:
          memory: "4Gi"
          cpu: "2000m"
      queryNode:
        requests:
          memory: "2Gi"
          cpu: "1000m"
        limits:
          memory: "8Gi"
          cpu: "4000m"
      indexNode:
        requests:
          memory: "1Gi"
          cpu: "500m"
        limits:
          memory: "4Gi"
          cpu: "2000m"
      proxy:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "512Mi"
          cpu: "500m"

    # 服务配置
    service:
      type: ClusterIP
      port: 19530
      metricsPort: 9091

    # 备份配置
    backup:
      enabled: true
      image:
        repository: milvusdb/milvus-backup
        tag: v0.4.0
      schedule: "0 3 * * *"  # 每天凌晨 3 点
      retentionDays: 30

    # 监控配置
    monitoring:
      enabled: true
      prometheusScrape: true

  # Elasticsearch（OpenMetadata 搜索后端）
  elasticsearch:
    enabled: true
    image:
      repository: docker.elastic.co/elasticsearch/elasticsearch
      tag: "8.10.2"
    persistence:
      size: 30Gi
      storageClass: standard-hdd
    resources:
      requests:
        memory: 1Gi
        cpu: 250m
      limits:
        memory: 2Gi
        cpu: 1000m
    config:
      discoveryType: single-node
      securityEnabled: false
      javaOpts: "-Xms512m -Xmx512m"

  # OpenMetadata 元数据治理平台
  openmetadata:
    enabled: true
    image:
      repository: openmetadata/server
      tag: "1.3.1"
      pullPolicy: IfNotPresent
    resources:
      requests:
        memory: 1Gi
        cpu: 500m
      limits:
        memory: 4Gi
        cpu: 2000m
    config:
      # 认证模式（no-auth / basic / ldap / saml / openid-connect）
      authenticationProvider: "no-auth"
      # Pipeline 服务（需要 Airflow）
      pipelineServiceEnabled: false
      # OpenMetadata 使用的数据库名
      database: "openmetadata_db"
    service:
      type: ClusterIP
      port: 8585

# ============================================
# 共享服务配置
# ============================================

services:
  # JWT Secret Key - REQUIRED for all service authentication
  # IMPORTANT: Generate a secure key with: openssl rand -base64 32
  # DO NOT use default/weak values in production
  jwtSecretKey: ""  # REQUIRED: set via JWT_SECRET_KEY environment variable

# ============================================
# Alldata 平台
# ============================================

alldata:
  enabled: true
  namespace: one-data-alldata

  image:
    repository: one-data/alldata-api
    tag: "v1.0.0"
    pullPolicy: IfNotPresent

  replicaCount: 2

  resources:
    requests:
      memory: 512Mi
      cpu: 250m
    limits:
      memory: 1Gi
      cpu: 500m

  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

  service:
    type: ClusterIP
    port: 8080

  ingress:
    enabled: true
    className: nginx
    host: alldata.example.com
    # SECURITY: TLS enabled by default for production security
    # Requires cert-manager or manually configured TLS secrets
    tls: true
    tlsSecretName: alldata-tls

  # Kettle ETL 引擎配置
  kettle:
    enabled: true

    image:
      repository: pentaho/kettle
      tag: "9.4.0.0-343"
      pullPolicy: IfNotPresent

    # Carte 服务器配置
    carte:
      enabled: true
      replicaCount: 2
      host: "0.0.0.0"
      port: 8081
      sslEnabled: false

      resources:
        requests:
          memory: "512Mi"
          cpu: "250m"
        limits:
          memory: "4096Mi"
          cpu: "2000m"

      service:
        type: ClusterIP
        port: 8081

    # Worker 配置 (Job 执行)
    worker:
      enabled: true
      replicaCount: 1

      resources:
        requests:
          memory: "512Mi"
          cpu: "250m"
        limits:
          memory: "4096Mi"
          cpu: "2000m"

    # 作业存储配置
    persistence:
      jobs:
        enabled: true
        size: 10Gi
        storageClass: nfs-storage  # ReadWriteMany required

      logs:
        enabled: true
        size: 5Gi
        storageClass: standard-hdd

    # Java 配置
    java:
      heapSize: "2048m"
      metaSpaceSize: "256m"

    # OpenLineage 集成
    openlineage:
      enabled: true
      apiUrl: "http://alldata-api.one-data-alldata.svc.cluster.local:8080/api/v1/lineage/events"
      namespace: "alldata"

    # OpenMetadata 集成
    openmetadata:
      syncEnabled: true
      host: "openmetadata.one-data-infra.svc.cluster.local"
      port: 8585

    # AI 增强功能
    ai:
      cleaningEnabled: true
      maskingEnabled: true
      imputationEnabled: true
      serviceUrl: "http://alldata-api.one-data-alldata.svc.cluster.local:8080"

    # 日志配置
    logging:
      level: "Basic"  # Minimal, Basic, Detailed, Debug, Rowlevel
      maxDays: 30

    # CronJob 配置
    cronJobs:
      dailySync:
        enabled: false
        schedule: "0 2 * * *"  # 每天凌晨 2 点

# ============================================
# Cube Studio 平台
# ============================================

cube:
  enabled: true
  namespace: one-data-cube

  # 模型服务配置
  modelServing:
    enabled: true
    image:
      repository: vllm/vllm-openai
      tag: v0.3.0
      pullPolicy: IfNotPresent

    replicaCount: 1

    # 模型配置
    model:
      name: Qwen/Qwen-0.5B-Chat
      maxModelLen: 2048
      tensorParallelSize: 1

    # GPU 配置（可选）
    gpu:
      enabled: false
      count: 1
      type: nvidia.com/gpu

    resources:
      requests:
        memory: 4Gi
        cpu: 1000m
      limits:
        memory: 8Gi
        cpu: 4000m

    service:
      type: ClusterIP
      port: 8000

    ingress:
      enabled: true
      className: nginx
      host: cube.example.com
      # SECURITY: TLS enabled by default for production security
      tls: true
      tlsSecretName: cube-tls

  # JupyterHub 配置（可选）
  jupyterhub:
    enabled: false
    image:
      repository: jupyterhub
      tag: 3.0.0
    resources:
      requests:
        memory: 1Gi
        cpu: 500m

# ============================================
# Bisheng 平台
# ============================================

bisheng:
  enabled: true
  namespace: one-data-bisheng

  image:
    repository: one-data/bisheng-api
    tag: "v1.0.0"
    pullPolicy: IfNotPresent

  replicaCount: 2

  # 外部服务依赖
  dependencies:
    alldataApiUrl: http://alldata-api.one-data-alldata.svc.cluster.local:8080
    cubeApiUrl: http://vllm-serving.one-data-cube.svc.cluster.local:8000

  resources:
    requests:
      memory: 512Mi
      cpu: 250m
    limits:
      memory: 1Gi
      cpu: 500m

  service:
    type: ClusterIP
    port: 8081

  ingress:
    enabled: true
    className: nginx
    host: bisheng.example.com
    # SECURITY: TLS enabled by default for production security
    # Requires cert-manager or manually configured TLS secrets
    tls: true
    tlsSecretName: bisheng-tls

# ============================================
# 监控
# ============================================

monitoring:
  # IMPORTANT: Monitoring enabled by default for production observability
  enabled: true
  namespace: one-data-system

  prometheus:
    enabled: true
    persistence:
      size: 20Gi

  grafana:
    enabled: true
    persistence:
      size: 5Gi
    # REQUIRED: Must be set via --set or values override
    # Example: helm install ... --set monitoring.grafana.adminPassword=$GRAFANA_ADMIN_PASSWORD
    adminPassword: ""  # REQUIRED: set via GRAFANA_ADMIN_PASSWORD

# ============================================
# 安全
# ============================================

security:
  # Keycloak 配置（可选）
  keycloak:
    enabled: false
    image:
      repository: quay.io/keycloak/keycloak
      tag: 23.0

  # Istio 注入
  istio:
    enabled: false
    gateway:
      enabled: false

# ============================================
# 资源配额
# ============================================

resourceQuota:
  enabled: false
  requests:
    cpu: "16"
    memory: "32Gi"
    nvidia.com/gpu: "2"
  limits:
    cpu: "32"
    memory: "64Gi"
    nvidia.com/gpu: "4"
